{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "736e4923",
   "metadata": {},
   "source": [
    "## 1. Provide an example of the concepts of Prior, Posterior, and Likelihood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a92a9c61",
   "metadata": {},
   "source": [
    "**Ans:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12185c95",
   "metadata": {},
   "source": [
    "Let's use a medical diagnosis example to illustrate the concepts of Prior, Posterior, and Likelihood:\n",
    "\n",
    "Imagine a patient undergoing a medical test to determine whether they have a rare disease, let's call it \"Disease X.\" We want to calculate the probability of the patient having the disease based on the test results.\n",
    "\n",
    "1. Prior Probability (Prior):\n",
    "   - Prior probability is our initial belief or estimate of the likelihood of the patient having Disease X before any test results are known.\n",
    "   - Let's say, based on historical data and known risk factors, the prior probability of a random person having Disease X is 2%.\n",
    "\n",
    "2. Likelihood (Likelihood):\n",
    "   - Likelihood is the probability of observing the test results (evidence) given the patient's disease status.\n",
    "   - In our case, the likelihood describes the probability of getting positive test results if the patient actually has Disease X and the probability of getting negative test results if the patient doesn't have the disease.\n",
    "   - Let's assume that the test has a sensitivity of 95% (it correctly identifies the disease in 95% of cases) and a specificity of 90% (it correctly identifies the absence of the disease in 90% of cases).\n",
    "\n",
    "3. Posterior Probability (Posterior):\n",
    "   - Posterior probability is the updated probability of the patient having Disease X after taking the test results into account. It's calculated using Bayes' Theorem.\n",
    "   - We want to find P(Disease X | Positive Test), which is the probability of the patient having the disease given that they received a positive test result.\n",
    "\n",
    "Now, let's calculate the Posterior Probability (P(Disease X | Positive Test)):\n",
    "\n",
    "Using Bayes' Theorem:\n",
    "\\[P(Disease X | Positive Test) = \\frac{P(Positive Test | Disease X) * P(Disease X)}{P(Positive Test)}\\]\n",
    "\n",
    "- Prior Probability (P(Disease X)): 2% or 0.02 (our initial belief).\n",
    "- Likelihood (P(Positive Test | Disease X)): 95% or 0.95 (the probability of a positive test result when having the disease).\n",
    "- Complement of Prior Probability (P(Not Disease X)): 1 - 0.02 = 0.98 (the probability of not having the disease).\n",
    "- Likelihood (P(Positive Test | Not Disease X)): 10% or 0.10 (the probability of a positive test result when not having the disease).\n",
    "\n",
    "Now, let's calculate P(Positive Test) using the law of total probability:\n",
    "\\[P(Positive Test) = P(Positive Test | Disease X) * P(Disease X) + P(Positive Test | Not Disease X) * P(Not Disease X)\\]\n",
    "\\[P(Positive Test) = (0.95 * 0.02) + (0.10 * 0.98) = 0.019 + 0.098 = 0.117\\]\n",
    "\n",
    "Now, we can calculate the Posterior Probability using Bayes' Theorem:\n",
    "\\[P(Disease X | Positive Test) = \\frac{0.95 * 0.02}{0.117} ≈ 0.163\\]\n",
    "\n",
    "So, the Posterior Probability of the patient having Disease X after receiving a positive test result is approximately 16.3%.\n",
    "\n",
    "In this example:\n",
    "- Prior Probability (Prior) represents our initial belief.\n",
    "- Likelihood (Likelihood) describes the test's accuracy.\n",
    "- Posterior Probability (Posterior) is the updated probability after considering the test results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c88160a1",
   "metadata": {},
   "source": [
    "## 2. What role does Bayes&#39; theorem play in the concept learning principle?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ab385fc",
   "metadata": {},
   "source": [
    "**Ans:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70cd1b83",
   "metadata": {},
   "source": [
    "Bayes' theorem plays a role in the concept learning principle by providing a probabilistic framework to update beliefs about the likelihood of a concept or hypothesis based on new evidence or data. In concept learning, Bayes' theorem helps in assessing the probability of a hypothesis being correct or incorrect given the observed data, allowing for the refinement of the learned concept. It enables a systematic and data-driven approach to concept learning, where prior beliefs are updated to form posterior beliefs based on the observed evidence, facilitating more accurate and informed concept acquisition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9295f5a4",
   "metadata": {},
   "source": [
    "## 3. Offer an example of how the Nave Bayes classifier is used in real life."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb5eaa72",
   "metadata": {},
   "source": [
    "**Ans:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb2851d",
   "metadata": {},
   "source": [
    "**Email Spam Filtering:**\n",
    "\n",
    "- **Problem**: The goal is to automatically classify incoming emails as either spam (unwanted or unsolicited emails) or non-spam (legitimate emails) to protect users from unwanted content and clutter in their inboxes.\n",
    "\n",
    "- **How Naïve Bayes is Used**:\n",
    "  - **Training Phase**: During the training phase, the classifier is provided with a labeled dataset of emails. Each email is tagged as spam or non-spam.\n",
    "  - **Feature Extraction**: The contents of each email are processed to extract relevant features, such as words or phrases. These features are used to build a vocabulary of terms.\n",
    "  - **Calculating Conditional Probabilities**: For each term in the vocabulary, the classifier calculates the conditional probabilities of that term occurring in spam emails and non-spam emails. This is done using Bayes' theorem and the training data.\n",
    "  - **Building a Model**: The classifier constructs a probabilistic model that assigns a probability to an incoming email being spam or non-spam based on the presence and frequency of terms from the vocabulary in the email.\n",
    "  - **Classification**: When a new email arrives, the Naïve Bayes classifier calculates the probability that the email is spam or non-spam based on the observed terms in the email.\n",
    "  - **Thresholding**: The classifier compares the calculated probabilities to a threshold (e.g., 0.5). If the probability of being spam is above the threshold, the email is classified as spam; otherwise, it's classified as non-spam."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385ce552",
   "metadata": {},
   "source": [
    "## 4. Can the Nave Bayes classifier be used on continuous numeric data? If so, how can you go about doing it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4406322",
   "metadata": {},
   "source": [
    "**Ans:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171f0cec",
   "metadata": {},
   "source": [
    "Yes, the Naïve Bayes classifier can be used on continuous numeric data, but it typically requires discretization or the use of probability density functions. \n",
    "\n",
    "Here's how you can go about using Naïve Bayes with continuous data:\n",
    "\n",
    "1. **Discretization**:\n",
    "   - One common approach is to discretize the continuous data into discrete bins or intervals. This allows you to treat the continuous data as categorical data.\n",
    "   - For example, if you have a dataset of people's ages, you can create age groups like \"under 20,\" \"20-30,\" \"30-40,\" and so on.\n",
    "   - After discretization, you can apply the standard Naïve Bayes classifier for categorical data.\n",
    "\n",
    "2. **Probability Density Functions (PDFs)**:\n",
    "   - Instead of discretization, you can use probability density functions to model the continuous data directly.\n",
    "   - You assume a probability distribution for the data, such as a Gaussian (normal) distribution for continuous data.\n",
    "   - You estimate the parameters (mean and variance) of the distribution from the training data for each class (e.g., spam and non-spam).\n",
    "   - When a new data point is presented, you calculate the likelihood of it belonging to each class using the PDF of the distribution.\n",
    "   - Bayes' theorem is then applied to compute the posterior probabilities for each class.\n",
    "   - The class with the highest posterior probability is the predicted class.\n",
    "\n",
    "3. **Kernel Density Estimation (KDE)**:\n",
    "   - KDE is a non-parametric approach that estimates the probability density function of the data without assuming a specific distribution.\n",
    "   - It's especially useful when the underlying data distribution is not known or when data is multimodal (has multiple peaks).\n",
    "   - KDE estimates the likelihood of a data point belonging to a class based on its density.\n",
    "\n",
    "4. **Naïve Bayes Variants**:\n",
    "   - There are variants of the Naïve Bayes classifier designed for continuous data, such as the Gaussian Naïve Bayes, which assumes a Gaussian distribution for each feature.\n",
    "   - Other variants include Multinomial Naïve Bayes (for count-based data) and Bernoulli Naïve Bayes (for binary data).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "200a3d02",
   "metadata": {},
   "source": [
    "## 5. What are Bayesian Belief Networks, and how do they work? What are their applications? Are they capable of resolving a wide range of issues?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97760247",
   "metadata": {},
   "source": [
    "**Ans:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f0b8ea",
   "metadata": {},
   "source": [
    "Bayesian Belief Networks (BBNs), also known as Bayesian Networks or Bayes Nets, are graphical models that represent probabilistic relationships among a set of variables. BBNs are used to encode and reason about uncertainty, making them a powerful tool in various fields. \n",
    "\n",
    "Here's an overview of BBNs:\n",
    "\n",
    "**How Bayesian Belief Networks Work:**\n",
    "\n",
    "1. **Graphical Structure:** BBNs consist of two main components: a directed acyclic graph (DAG) and conditional probability tables (CPTs). In the graph:\n",
    "   - Nodes represent random variables or events.\n",
    "   - Directed edges indicate probabilistic dependencies between variables. An arrow from node A to node B implies that A influences B.\n",
    "\n",
    "2. **Conditional Probability Tables (CPTs):** Each node has an associated CPT that specifies the conditional probabilities of the node given its parent nodes in the graph. These tables capture the probabilistic relationships among variables.\n",
    "\n",
    "3. **Propagation:** BBNs allow for efficient probabilistic inference. Given evidence (observed values) for some variables, BBNs can propagate this evidence to calculate the probabilities of other variables in the network.\n",
    "\n",
    "4. **Updating Beliefs:** BBNs can update beliefs about a variable as new evidence becomes available. This makes them suitable for dynamic scenarios where information evolves over time.\n",
    "\n",
    "**Applications of Bayesian Belief Networks:**\n",
    "\n",
    "BBNs have a wide range of applications, including:\n",
    "\n",
    "1. **Medical Diagnosis:** BBNs are used to assist doctors in diagnosing diseases and medical conditions by combining patient symptoms and test results to provide probabilistic diagnoses.\n",
    "\n",
    "2. **Risk Assessment:** BBNs help assess risks in various domains, such as finance, insurance, and project management, by modeling uncertainties and identifying potential risks and their impacts.\n",
    "\n",
    "3. **Natural Language Processing:** BBNs can model language structures, semantics, and disambiguation for applications like speech recognition, machine translation, and sentiment analysis.\n",
    "\n",
    "4. **Criminal Justice:** BBNs aid in criminal profiling, decision support for law enforcement, and predicting criminal activities by considering various pieces of evidence and indicators.\n",
    "\n",
    "5. **Environmental Modeling:** BBNs are used to model complex ecosystems, climate systems, and pollution propagation to assess environmental risks and make informed decisions.\n",
    "\n",
    "6. **Quality Control:** BBNs can help improve quality control processes by modeling production defects, identifying root causes, and optimizing manufacturing processes.\n",
    "\n",
    "**Capability and Limitations:**\n",
    "\n",
    "BBNs are versatile and can handle complex, real-world problems by explicitly modeling and reasoning about uncertainty. They provide a structured way to combine domain knowledge with data to make informed decisions. However, they do have some limitations:\n",
    "\n",
    "1. **Scalability:** As the number of variables and dependencies increases, BBNs can become computationally expensive.\n",
    "\n",
    "2. **Data Requirements:** BBNs require substantial data for parameter estimation and may not perform well with limited data.\n",
    "\n",
    "3. **Model Assumptions:** The \"Naïve Bayes\" assumption of conditional independence between parent nodes for each node may not hold in all situations, potentially leading to inaccuracies.\n",
    "\n",
    "4. **Complexity:** Building BBNs can be complex and requires expertise in modeling and domain knowledge.\n",
    "\n",
    "In summary, Bayesian Belief Networks are powerful tools for modeling and reasoning about uncertainty, making them suitable for a wide range of applications. However, their performance depends on the quality of data and the modeling process. They are capable of addressing diverse problems but should be used thoughtfully to address the specific requirements of each problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02197ffb",
   "metadata": {},
   "source": [
    "## 6. Passengers are checked in an airport screening system to see if there is an intruder. Let I be the random variable that indicates whether someone is an intruder I = 1) or not I = 0), and A be the variable that indicates alarm I = 0). If an intruder is detected with probability P(A = 1|I = 1) = 0.98 and a non-intruder is detected with probability P(A = 1|I = 0) = 0.001, an alarm will be triggered, implying the error factor. The likelihood of an intruder in the passenger population is P(I = 1) = 0.00001. What are the chances that an alarm would be triggered when an individual is actually an intruder?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76386e20",
   "metadata": {},
   "source": [
    "### Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808b79d3",
   "metadata": {},
   "source": [
    "\n",
    "   $P(T = 1 | A = 1) = P(A = 1 | T = 1) * P(T = 1) / P(A = 1)$\n",
    "   \n",
    "   \n",
    "\n",
    "   $P(T = 1 | A = 1) = [P(A = 1 | T = 1) * P(T = 1)] / [P(A = 1 | T = 1) * P(T = 1) + P(A = 1 | T = 0) * P(T = 0)]$\n",
    "\n",
    "\n",
    "\n",
    "  $P(T = 1 | A = 1) = [0.98 * 0.00001] / [0.98 * 0.00001 + 0.001 * (1 - 0.00001)]$\n",
    "\n",
    "\n",
    "\n",
    "   $P(T = 1 | A = 1) ≈ 0.0097$\n",
    "   \n",
    "\n",
    "So, the probability of event T = 1 occurring given that event A = 1 has occurred is approximately 0.01."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e182ec",
   "metadata": {},
   "source": [
    "## 7. An antibiotic resistance test (random variable T) has 1% false positives (i.e., 1% of those who are not immune to an antibiotic display a positive result in the test) and 5% false negatives (i.e., 1% of those who are not resistant to an antibiotic show a positive result in the test) (i.e. 5 percent of those actually resistant to an antibiotic test negative). Assume that 2% of those who were screened were antibiotic-resistant. Calculate the likelihood that a person who tests positive is actually immune (random variable D)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "057cbe23",
   "metadata": {},
   "source": [
    "### Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af84c9f6",
   "metadata": {},
   "source": [
    "- T = p means Test positive,\n",
    "\n",
    "- T = n means Test negative,\n",
    "\n",
    "- D = p means person takes antibiotics,\n",
    "\n",
    "- D = n means person does not take antibiotics\n",
    "\n",
    "We know:\n",
    "\n",
    "$$P(T=p|D=n) = 0.01   (false positives)$$\n",
    "\n",
    "\n",
    "$$(false negatives)  P(T=n|D=p) = 0.05 =⇒ P(T=p|D=p) = 0.95    (true positives)$$\t\n",
    "\n",
    "$$P(D=p) = 0.02 =⇒ P(D=n) = 0.98$$\n",
    "\n",
    "\n",
    "We want to know the probability that somebody who tests positive is actually taking antibiotics:\n",
    "\n",
    "\n",
    "$$P(D=p|T=p) = \\frac{P(T=p|D=p)P(D=p)}{P(T = p)}$$ (Bayes theorem)\n",
    "\n",
    "We do not know $P(T = p)$:\n",
    "\n",
    "$$P(T=p)= P(T=p|D=p)P(D = p) + P(T=p|D=n)P(D=n)$$\n",
    "\n",
    "\n",
    "We get:\n",
    "\n",
    "\n",
    "$$P(D=p|T=p)=\\frac{P(T = p|D = p)P(D = p)}{P(T = p)}$$\n",
    "\n",
    "\n",
    " $$=\\frac{P(T=p|D=p)P(D = p)}{P(T = p|D = p)P(D = p)+P(T=p|D=n)P(D = n)}$$\n",
    "\n",
    "$$=\\frac{0.95 • 0.02}{0.95 • 0.02 + 0.01 • 0.98}$$\n",
    " \n",
    "$$= 0.019/0.0288 ≈ 0.66$$\n",
    "\n",
    "\n",
    "There is a chance of only two thirds that someone with a positive test is actually taking antibiotics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f460a81",
   "metadata": {},
   "source": [
    "## 8. In order to prepare for the test, a student knows that there will be one question in the exam that is either form A, B, or C. The chances of getting an A, B, or C on the exam are 30 percent, 20%, and 50 percent, respectively. During the planning, the student solved 9 of 10 type A problems, 2 of 10 type B problems, and 6 of 10 type C problems.\n",
    "### 1. What is the likelihood that the student can solve the exam problem?\n",
    "### 2. Given the student&#39;s solution, what is the likelihood that the problem was of form A?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebe0c22b",
   "metadata": {},
   "source": [
    "### Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4e4ce8",
   "metadata": {},
   "source": [
    "### 1.\n",
    "\n",
    "\n",
    "$P (solved)   =   P (solved|A)P (A) + P (solved|B)P (B) + P (solved|C)P (C)$\n",
    "\n",
    "\n",
    "=9/10 • 30% + 2/10 • 20% + 6/10 • 50\n",
    "\n",
    "\n",
    "=27/100 + 4/100 + 30/100 = 61/100 = 0.614\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d190e3c",
   "metadata": {},
   "source": [
    "## 2.\n",
    "\n",
    "$P(A|solved)= P(solved|A)P(A)/P(solved)$\n",
    " \n",
    "\n",
    " \n",
    "= (9/10•30%)/(61/100) = (27/100)/(61/100) = 27/61 = 0.442\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18884b92",
   "metadata": {},
   "source": [
    "## 9. A bank installs a CCTV system to track and photograph incoming customers. Despite the constant influx of customers, we divide the timeline into 5 minute bins. There may be a customer coming into the bank with a 5% chance in each 5-minute time period, or there may be no customer (again, for simplicity, we assume that either there is 1 customer or none, not the case of multiple customers). If there is a client, the CCTV will detect them with a 99 percent probability. If there is no customer, the camera can take a false photograph with a 10% chance of detecting movement from other objects.\n",
    "### 1. How many customers come into the bank on a daily basis (10 hours)?\n",
    "### 2. On a daily basis, how many fake photographs (photographs taken when there is no customer) and how many missed photographs (photographs taken when there is a customer) are there?\n",
    "### 3. Explain likelihood that there is a customer if there is a photograph?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f42ee18",
   "metadata": {},
   "source": [
    "### Solution:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4f0e35",
   "metadata": {},
   "source": [
    "## 1.\n",
    "\n",
    "\n",
    "There are 10×12 = 120 five-minute periods per day\n",
    "\n",
    "In each period there is a probability of 5%  customers being present. \n",
    "\n",
    "Thus the average number of cutomers is 120×5% = 120×0.05 = 6.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d445175",
   "metadata": {},
   "source": [
    "# 2.\n",
    "\n",
    "On average there is no cutomer in (120 − 6) of the five-minute periods. \n",
    "\n",
    "This times the probability of 10% per period for a fake photographs yields (120 − 6) × 10% = 114 × 0.1 = 11.4 fake photographs.\n",
    "\n",
    "\n",
    "On average there are 6 customers, each of which has a probability of 1% of getting missed. Thus the number of missed photographs is \n",
    "\n",
    "6 × 1% = 6 × 0.01 = 0.06."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036b3cf2",
   "metadata": {},
   "source": [
    "# 3.\n",
    "\n",
    "\n",
    "For this question we need Bayes theorem.\n",
    "\n",
    "\n",
    "$$P(customer|photograph) = \\frac{P(photograph|customer)P(customer)}{P(photograph)}$$\n",
    "\n",
    "$$=\\frac{P(photograph|customer)P(customer)}{P(photograph|customer)P(customer) + P((photograph|no customer)P(no customer)}$$\n",
    "\n",
    "$$=\\frac{(0.99)(0.05)}{(0.99)(0.05) + (0.1)(1 − 0.05)}$$\n",
    "\n",
    "$$= 0.34256055363321797$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a2b52a",
   "metadata": {},
   "source": [
    "## 10. Create the conditional probability table associated with the node Won Toss in the Bayesian Belief network to represent the conditional independence assumptions of the Nave Bayes classifier for the match winning prediction problem in Section 6.4.4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8639d43",
   "metadata": {},
   "source": [
    "### Solution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c77da778",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Outcome</th>\n",
       "      <th>Won Toss</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes (Win)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes (Win)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No (Lose)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No (Lose)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Match Outcome  Won Toss  Probability\n",
       "0     Yes (Win)         1          0.6\n",
       "1     Yes (Win)         0          0.4\n",
       "2     No (Lose)         1          0.3\n",
       "3     No (Lose)         0          0.7"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## I dont have the access of Section 6.4.4. so assuming the data from my side\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame for the conditional probability table\n",
    "data = {\n",
    "    'Match Outcome': ['Yes (Win)', 'Yes (Win)', 'No (Lose)', 'No (Lose)'],\n",
    "    'Won Toss': [1, 0, 1, 0],\n",
    "    'Probability': [0.6, 0.4, 0.3, 0.7]  # Hypothetical probabilities\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0188635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Won Toss         0    1\n",
      "Match Outcome          \n",
      "No (Lose)      0.7  0.3\n",
      "Yes (Win)      0.4  0.6\n"
     ]
    }
   ],
   "source": [
    "# Pivot the table for a more structured view\n",
    "cpt = df.pivot(index='Match Outcome', columns='Won Toss', values='Probability')\n",
    "\n",
    "# Fill missing values with zeros\n",
    "cpt = cpt.fillna(0)\n",
    "\n",
    "print(cpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bae4d56a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
